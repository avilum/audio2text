{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wav2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avilum/audio2text/blob/master/wav2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "D5HcNX3BUeEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers librosa torch"
      ],
      "metadata": {
        "id": "Jwd5AMMHUdxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ],
      "metadata": {
        "id": "g-iGMNICO4J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model and tokenizer\n",
        "_model = \"facebook/wav2vec2-large-960h\"\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(_model)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(_model)"
      ],
      "metadata": {
        "id": "a2aDGVOMO9N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8586a593-d1da-41b9-f28a-4f75f790ccad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:746: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load any audio file of your choice\n",
        "# speech, rate = librosa.load(\"~/Desktop/hi.wav\",sr=8000)\n",
        "speech, rate = librosa.load(\"Desktop/hi.m4a\",sr=16000) # SHOULD BE 'HAMBURGER WITH BACON'..."
      ],
      "metadata": {
        "id": "sNt2UoqQPKd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d686faf0-da9b-4468-e039-1bc9e541c850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  return f(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Speech:', speech)\n",
        "print('Shape:', speech.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNX4tUoWYAZV",
        "outputId": "19b8a655-ceff-4419-a2af-b45154a306ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech: [0.00128225 0.00222278 0.00200444 ... 0.02562797 0.03500057 0.        ]\n",
            "Shape: (49131,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display as ipd\n",
        "ipd.Audio(speech, rate=rate)"
      ],
      "metadata": {
        "id": "kr2oNctITzP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "input_values = tokenizer(speech, return_tensors = 'pt').input_values\n",
        "\n",
        "# Inference\n",
        "# Store logits (non-normalized predictions)\n",
        "logits = model(input_values).logits\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "Y31vSbiFTCqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea4c660-d7ce-4da9-8bf1-00110bcb0be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 153, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Postprocessing - Getting the predicted vectors words id's in the speech array\n",
        "predicted_ids = torch.argmax(logits, dim =-1)\n",
        "\n",
        "# Decoding the audio to generate text (length derived from the sampling rate)\n",
        "transcriptions = tokenizer.decode(predicted_ids[0])\n",
        "print(transcriptions)"
      ],
      "metadata": {
        "id": "AT-5qoOcTFhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616792c9-502d-4163-fb6d-4631f4cf1f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEMBURGER WITH BACON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_ids[0].shape"
      ],
      "metadata": {
        "id": "vUdnDzPsHSib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac050d9d-418b-4f76-aec5-fd42ae07b01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([153])"
            ]
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# E2E simplified:\n",
        "_model = \"facebook/wav2vec2-large-960h\"\n",
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(_model)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(_model)\n",
        "processor = Wav2Vec2Processor.from_pretrained(_model)\n",
        "\n",
        "# Load the file for inference\n",
        "speech, rate = librosa.load(\"Desktop/hi.m4a\",sr=16000)\n",
        "input_values = processor(speech, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
        " \n",
        "# retrieve logits (inference)\n",
        "logits = model(input_values).logits\n",
        "\n",
        "# take argmax and decode (postprocessing)\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "\n",
        "# Print the text\n",
        "print(transcription)\n",
        "\n",
        "# continue with your app... :) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pme7JliMdhRk",
        "outputId": "c12ca956-8b6a-411d-f263-f64197213120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:746: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  return f(*args, **kwargs)\n",
            "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HEMBURGER WITH BACON']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second inference is much faster...\n",
        "logits = model(input_values).logits\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bC1EMLhiINv",
        "outputId": "c84b69d8-e862-49e1-aed9-40175182eb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HEMBURGER WITH BACON']\n"
          ]
        }
      ]
    }
  ]
}